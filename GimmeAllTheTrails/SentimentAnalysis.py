import pandas as pd
from textblob import TextBlob

from GimmeAllTheTrails.utils.Contraction_map import (
    process_text,
    subjectivity,
    polarity,
    sent_Analysis,
)


class Sentiment_Analysis(object):

    """
    load written reviews dataset in this class and clean them
    """

    def __init__(self, file_dir):
        self.file_dir = file_dir
        self.dataset = pd.read_csv(self.file_dir)
        self.cleaned_data = self.cleaning_trails_reviews()

    # Create a function to get the subjectivity
    def subjectivity_2(self):
        return TextBlob(self.dataset["processed_reviews"]).sentiment.subjectivity

    # Create a function to get the polarity
    def polarity_2(self):
        return TextBlob(self.dataset["processed_reviews"]).sentiment.polarity

    @staticmethod
    def sent_Analysis_2(score):
        if score < 0:
            return "Negative"
        elif score == 0:
            return "Neutral"
        else:
            return "Positive"

    def cleaning_trails_reviews(self) -> pd.DataFrame:
        """
        get the lat lon pairs and associated name pairs for each hiking trail location
        :return:
        """
        # get coords and trail id
        trail_reviews = self.dataset["reviews"]
        print(self.dataset.shape)
        # Removing missing values if any
        nan_value = float("NaN")
        self.dataset.replace(" ", nan_value, inplace=True)
        self.dataset = self.dataset.dropna()
        self.dataset["text_reviews"] = self.dataset["reviews"].apply(
            lambda x: x.strip(",")
            .replace("\n\n\n", "")
            .replace('"', "")
            .replace("'", "")
            .replace("â€¢", ",")
            .lstrip(", ")
        )
        print(self.dataset["text_reviews"])
        # converting the list to string
        self.dataset["processed_reviews"] = self.dataset["text_reviews"].apply(
            lambda x: x[1:-1]
        )
        self.dataset["clean_reviews"] = self.dataset["processed_reviews"].apply(
            process_text
        )
        print(self.dataset["clean_reviews"])
        self.dataset["clean_reviews"] = self.dataset["clean_reviews"].apply(
            lambda x: " ".join(x)
        )
        print(self.dataset["clean_reviews"])
        self.dataset["Subjectivity"] = self.dataset["processed_reviews"].apply(
            subjectivity
        )
        self.dataset["Polarity"] = self.dataset["processed_reviews"].apply(polarity)
        self.dataset["Analysis"] = self.dataset["Polarity"].apply(sent_Analysis)
        print(self.dataset.head(10))


def make_sentiment_csv(written_csv_dir, outfile):
    """
    applies sentiment algo to data,
    :param written_csv_dir: location of written_reviews.csv file
    :param outfile: location to output resultant csv file
    :return: None
    """
    sentiment = Sentiment_Analysis(written_csv_dir)
    sentiment.dataset.to_csv(outfile)


#################################################################################


# #Positive tweets
# positive_words = ' '.join([text for text in self.dataset['clean_reviews'][self.dataset['Analysis'] == "Positive"]])
# #wordcloud = WordCloud(width=800, height=500,random_state=21, max_font_size=110).generate(positive_words)
# #plt.figure(figsize=(10, 7))
# #plt.imshow(wordcloud, interpolation="bilinear")
# #plt.axis('off')
# #plt.figtext(.5,.8,title,fontsize = 20, ha='center')
# #plt.show()
#
# negative_words = ' '.join([text for text in self.dataset['clean_reviews'][self.dataset['Analysis'] == "Negative"]])
# # Create wordcloud
#
# print(self.dataset.loc[self.dataset['Analysis'] == "Negative"])
# negative = []
#  # build negative review list
# for i in range(len(self.dataset.loc[self.dataset['Analysis'] == "Negative"])):
#     negative.append(self.dataset['clean_reviews'][i])
#
# neg_reviews = pd.DataFrame(negative,columns = ['negative_reviews'])
# best_lda_model, dtm_tfidf, tfidf_vectorizer = optimal_lda_model(neg_reviews, 'negative_reviews')
#
# # Topic Modelling Visualization for the Negative Reviews
# #vis_data = gensimvis.prepare(best_lda_model, dtm_tfidf, tfidf_vectorizer)
# vis_data = pyLDAvis.sklearn.prepare(best_lda_model, dtm_tfidf, tfidf_vectorizer)
# pyLDAvis.show(vis_data)


if __name__ == "__main__":
    make_sentiment_csv("data/csv/written_reviews.csv", "data/csv/sentiment.csv")
